{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (procesamiento de lenguaje natural) con Python\n",
    "\n",
    "¡Este es el notebook que estaremos viendo como aplicar NLP!\n",
    "\n",
    "En esta ocasión discutiremos una descripción general de nivel superior de los conceptos básicos del procesamiento del lenguaje natural, que básicamente consiste en combinar técnicas de aprendizaje automático con texto y usar matemáticas y estadísticas para obtener ese texto en un formato que los algoritmos de aprendizaje automático puedan entender.\n",
    "\n",
    "Una vez que haya completado esta lección, tendrá un proyecto que utiliza algunos datos de texto de Yelp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Primero debemos correr los códigos siguientes para instalar la librería NLTK \n",
    "\n",
    "#conda install nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos un conjunto de datos de los [UCI datasets](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection). Este conjunto de datos ya se encuentra en la carpeta de esta sección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo que estamos usando contiene una colección de más de 5 mil mensajes telefónicos SMS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mensaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            mensaje\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = pd.read_excel('sms.xlsx')\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio de Datos\n",
    "\n",
    "¡Veamos algunas de las estadísticas con algunos gráficos y los métodos incorporados en pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mensaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5571</td>\n",
       "      <td>5571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4824</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 mensaje\n",
       "count   5571                    5571\n",
       "unique     2                    5168\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4824                      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos **groupby** para usar describe por etiqueta, de esta manera podemos comenzar a pensar en las características que separan el ham y el spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">mensaje</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4824</td>\n",
       "      <td>4515</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mensaje                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4824   4515                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A medida que continuamos con nuestro análisis, queremos empezar a pensar en las funciones que vamos a utilizar. Esto va de la mano con la idea general de [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering). Cuanto mejor sea su conocimiento de dominio sobre los datos, mejor será su capacidad para diseñar más funciones a partir de ellos. La ingeniería de variables es una parte muy importante de la detección de spam en general. ¡Te animo a leer sobre el tema!\n",
    "\n",
    "Hagamos una nueva columna para detectar el largo de los mensajes de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mensaje</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            mensaje  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['length'] = messages['mensaje'].str.len()\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaciones\n",
    "Vamos a graficar.. importar librerías primero.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages['length'].plot(bins=50, kind='hist') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Juega con el tamaño de los bins! ¡Parece que la longitud del texto puede ser una buena característica en la que pensar! Intentemos explicar por qué el eje x llega hasta casi 1000, ¡esto debe significar que hay un mensaje realmente largo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5571.000000\n",
       "mean       80.503859\n",
       "std        59.939294\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Woah! 910 caracteres, usemos filtrado para encontrar este mensaje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[messages['length'] == 910]['mensaje'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Parece que tenemos una especie de Romeo enviando mensajes de texto! Pero volvamos a centrarnos en la idea de tratar de ver si la longitud del mensaje es una característica distintiva entre ham y spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'ham'}>,\n",
       "       <AxesSubplot:title={'center':'spam'}>], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Muy interesante! A través de la EDA básica, hemos podido descubrir una tendencia según la cual los mensajes de spam tienden a tener más caracteres. (¡Lo siento Romeo!)\n",
    "\n",
    "¡Ahora comencemos a procesar los datos para que eventualmente podamos usarlos con SciKit Learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro principal problema con nuestros datos es que están todos en formato de texto (cadenas). Los algoritmos de clasificación que hemos aprendido hasta ahora necesitarán algún tipo de vector de características numéricas para realizar la tarea de clasificación. En realidad, existen muchos métodos para convertir un corpus a formato vectorial. El más simple es el enfoque de [bolsa-de-palabras](http://en.wikipedia.org/wiki/Bag-of-words_model), donde cada palabra única en un texto estará representada por un número.\n",
    "\n",
    "\n",
    "En esta sección convertiremos los mensajes sin formato (secuencia de caracteres) en vectores (secuencias de números).\n",
    "\n",
    "Como primer paso, escribamos una función que dividirá un mensaje en sus palabras individuales y devolverá una lista. También eliminaremos palabras muy comunes, ('de', 'el', etc.). Para ello aprovecharemos la biblioteca NLTK. Es prácticamente la biblioteca estándar en Python para procesar texto y tiene muchas características útiles. Aquí solo usaremos algunos de los básicos.\n",
    "\n",
    "Creemos una función que procese la cadena en la columna del mensaje, luego podemos usar **apply()** para que los pandas procesen todo el texto en el DataFrame.\n",
    "\n",
    "Primero eliminando la puntuación. Podemos aprovechar la biblioteca **string** incorporada de Python para obtener una lista rápida de toda la puntuación posible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "#puntuaciones en string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = 'Sample message! Notice: it has punctuation.'\n",
    "\n",
    "# verifica si algun caracter (letra o numero o simbolo) es una puntuacion y no la toma del texto\n",
    "nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'a',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 'N',\n",
       " 'o',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'n',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# une todos los caracteres como palabras\n",
    "nopunc = ''.join(nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample message Notice it has punctuation'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos cómo eliminar las palabras vacías (stopwords). Podemos imponer una lista de palabras vacías en inglés de NLTK (consulte la documentación para obtener más idiomas e información)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english')[0:10]) # muestra algunas stopwords\n",
    "print(stopwords.words('spanish')[0:10]) # muestra algunas stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sample', 'message', 'Notice', 'it', 'has', 'punctuation']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora a eliminar las stopwords\n",
    "clean_mess = [palabras for palabras in nopunc.split() if palabras.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sample', 'message', 'Notice', 'punctuation']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put both of these together in a function to apply it to our DataFrame later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Toma una cadena de texto y luego realiza lo siguiente:\n",
    "    1. Elimina toda la puntuación\n",
    "    2. Quite todas las palabras vacías\n",
    "    3. Devuelve una lista del texto limpio.\n",
    "    \"\"\"\n",
    "    # Verifique los caracteres para ver si están en puntuación\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Vuelve a unir a los personajes para formar la cadena.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Ahora solo elimina las stopwords\n",
    "    return [palabras for palabras in nopunc.split() if palabras.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mensaje</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            mensaje  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a \"tokenizar\" estos mensajes. La tokenización es solo el término utilizado para describir el proceso de convertir las cadenas de texto normales en una lista de tokens (palabras que realmente queremos).\n",
    "\n",
    "Veamos una salida de ejemplo en la columna:\n",
    "\n",
    "**Nota:**\n",
    "Es posible que recibamos algunas advertencias o errores por símbolos que no tuvimos en cuenta o que no estaban en Unicode (como un símbolo de libra esterlina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: mensaje, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# revisemos si la funcion text_process para limpiar los registros funciona\n",
    "messages['mensaje'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuando la normalización\n",
    "\n",
    "Hay muchas formas de seguir normalizando este texto. Como [Stemming](https://en.wikipedia.org/wiki/Stemming) o distinguir por [part of speech](http://www.nltk.org/book/ch05.html) (parte de un discurso).\n",
    "\n",
    "NLTK tiene muchas herramientas integradas y excelente documentación sobre muchos de estos métodos. A veces no funcionan bien para los mensajes de texto debido a la forma en que muchas personas tienden a usar abreviaturas o taquigrafía, por ejemplo:\n",
    "    \n",
    "    klk manito en k tu ta?\n",
    "    \n",
    "versus\n",
    "\n",
    "    Hola, que haces?\n",
    "    \n",
    "Algunos métodos de normalización de texto tendrán problemas con este tipo de taquigrafía, por lo que te dejaré explorar esos métodos más avanzados a través del [NLTK book online](http://www.nltk.org/book/).\n",
    "\n",
    "Por ahora solo nos enfocaremos en usar lo que tenemos para convertir nuestra lista de palabras en un vector real que SciKit-Learn pueda usar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente, tenemos los mensajes como listas de tokens (también conocidos como [lemmas](http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)) y ahora Necesito convertir cada uno de esos mensajes en un vector con el que los modelos de algoritmos de SciKit Learn puedan trabajar.\n",
    "\n",
    "Ahora convertiremos cada mensaje, representado como una lista de tokens (lemas) arriba, en un vector que los modelos de aprendizaje automático puedan entender.\n",
    "\n",
    "Lo haremos en tres pasos usando el modelo de bolsa de palabras:\n",
    "\n",
    "1. Cuente cuántas veces aparece una palabra en cada mensaje (conocida como frecuencia de término)\n",
    "\n",
    "2. Pese los recuentos, de modo que los tokens frecuentes tengan un peso menor (frecuencia de documento inversa)\n",
    "\n",
    "3. Normalice los vectores a la longitud unitaria, para abstraer la longitud del texto original (norma L2)\n",
    "\n",
    "Comencemos el primer paso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada vector tendrá tantas dimensiones como palabras únicas en el corpus de SMS. Primero usaremos **CountVectorizer** de SciKit Learn. Este modelo convertirá una colección de documentos de texto en una matriz de recuentos de tokens.\n",
    "\n",
    "Podemos imaginar esto como una matriz bidimensional. Donde la 1 dimensión es el vocabulario completo (1 fila por palabra) y la otra dimensión son los documentos reales, en este caso una columna por mensaje de texto.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "<table border = “1“>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Dado que hay tantos mensajes, podemos esperar muchos recuentos de cero para la presencia de esa palabra en ese documento. Debido a esto, SciKit Learn generará una [Sparse Matrix](https://en.wikipedia.org/wiki/Sparse_matrix) (Matriz dispersa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchos argumentos y parámetros que se pueden pasar al CountVectorizer. En esta ocasión solo usaremos el analyzer que sirve para aplicar una función a los registros, en este caso será nuestra funcion text_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación de la bolsa de palabras puede que tarde un poco...\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(messages['mensaje'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos algunas caracateristicas de las bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Go': 2059,\n",
       " 'jurong': 7554,\n",
       " 'point': 8916,\n",
       " 'crazy': 5768,\n",
       " 'Available': 1109,\n",
       " 'bugis': 5217,\n",
       " 'n': 8335,\n",
       " 'great': 6936,\n",
       " 'world': 11162,\n",
       " 'la': 7667,\n",
       " 'e': 6216,\n",
       " 'buffet': 5216,\n",
       " 'Cine': 1482,\n",
       " 'got': 6905,\n",
       " 'amore': 4652,\n",
       " 'wat': 10964,\n",
       " 'Ok': 3063,\n",
       " 'lar': 7700,\n",
       " 'Joking': 2450,\n",
       " 'wif': 11071,\n",
       " 'u': 10697,\n",
       " 'oni': 8589,\n",
       " 'Free': 1940,\n",
       " 'entry': 6330,\n",
       " '2': 423,\n",
       " 'wkly': 11122,\n",
       " 'comp': 5618,\n",
       " 'win': 11083,\n",
       " 'FA': 1832,\n",
       " 'Cup': 1550,\n",
       " 'final': 6556,\n",
       " 'tkts': 10511,\n",
       " '21st': 443,\n",
       " 'May': 2803,\n",
       " '2005': 430,\n",
       " 'Text': 3952,\n",
       " '87121': 870,\n",
       " 'receive': 9251,\n",
       " 'questionstd': 9158,\n",
       " 'txt': 10685,\n",
       " 'rateTCs': 9199,\n",
       " 'apply': 4730,\n",
       " '08452810075over18s': 73,\n",
       " 'U': 4067,\n",
       " 'dun': 6203,\n",
       " 'say': 9553,\n",
       " 'early': 6221,\n",
       " 'hor': 7185,\n",
       " 'c': 5260,\n",
       " 'already': 4628,\n",
       " 'Nah': 2947,\n",
       " 'dont': 6122,\n",
       " 'think': 10432,\n",
       " 'goes': 6876,\n",
       " 'usf': 10798,\n",
       " 'lives': 7841,\n",
       " 'around': 4776,\n",
       " 'though': 10449,\n",
       " 'FreeMsg': 1942,\n",
       " 'Hey': 2221,\n",
       " 'darling': 5863,\n",
       " '3': 543,\n",
       " 'weeks': 11010,\n",
       " 'word': 11149,\n",
       " 'back': 4892,\n",
       " 'Id': 2345,\n",
       " 'like': 7799,\n",
       " 'fun': 6754,\n",
       " 'still': 10092,\n",
       " 'Tb': 3929,\n",
       " 'ok': 8566,\n",
       " 'XxX': 4378,\n",
       " 'std': 10072,\n",
       " 'chgs': 5466,\n",
       " 'send': 9640,\n",
       " '£150': 11370,\n",
       " 'rcv': 9208,\n",
       " 'Even': 1801,\n",
       " 'brother': 5192,\n",
       " 'speak': 9970,\n",
       " 'treat': 10628,\n",
       " 'aids': 4589,\n",
       " 'patent': 8760,\n",
       " 'per': 8795,\n",
       " 'request': 9355,\n",
       " 'Melle': 2813,\n",
       " 'Oru': 3097,\n",
       " 'Minnaminunginte': 2832,\n",
       " 'Nurungu': 3022,\n",
       " 'Vettam': 4169,\n",
       " 'set': 9663,\n",
       " 'callertune': 5291,\n",
       " 'Callers': 1420,\n",
       " 'Press': 3277,\n",
       " '9': 908,\n",
       " 'copy': 5715,\n",
       " 'friends': 6718,\n",
       " 'Callertune': 1421,\n",
       " 'WINNER': 4220,\n",
       " 'valued': 10827,\n",
       " 'network': 8405,\n",
       " 'customer': 5819,\n",
       " 'selected': 9627,\n",
       " 'receivea': 9252,\n",
       " '£900': 11411,\n",
       " 'prize': 9057,\n",
       " 'reward': 9412,\n",
       " 'claim': 5518,\n",
       " 'call': 5274,\n",
       " '09061701461': 219,\n",
       " 'Claim': 1484,\n",
       " 'code': 5573,\n",
       " 'KL341': 2476,\n",
       " 'Valid': 4160,\n",
       " '12': 326,\n",
       " 'hours': 7200,\n",
       " 'mobile': 8215,\n",
       " '11': 315,\n",
       " 'months': 8250,\n",
       " 'R': 3320,\n",
       " 'entitled': 6327,\n",
       " 'Update': 4127,\n",
       " 'latest': 7715,\n",
       " 'colour': 5593,\n",
       " 'mobiles': 8216,\n",
       " 'camera': 5303,\n",
       " 'Call': 1416,\n",
       " 'Mobile': 2851,\n",
       " 'Co': 1491,\n",
       " 'FREE': 1864,\n",
       " '08002986030': 58,\n",
       " 'Im': 2351,\n",
       " 'gonna': 6889,\n",
       " 'home': 7158,\n",
       " 'soon': 9930,\n",
       " 'want': 10944,\n",
       " 'talk': 10302,\n",
       " 'stuff': 10152,\n",
       " 'anymore': 4700,\n",
       " 'tonight': 10556,\n",
       " 'k': 7560,\n",
       " 'Ive': 2393,\n",
       " 'cried': 5782,\n",
       " 'enough': 6318,\n",
       " 'today': 10523,\n",
       " 'SIX': 3494,\n",
       " 'chances': 5410,\n",
       " 'CASH': 1352,\n",
       " '100': 294,\n",
       " '20000': 427,\n",
       " 'pounds': 8974,\n",
       " 'CSH11': 1404,\n",
       " '87575': 874,\n",
       " 'Cost': 1523,\n",
       " '150pday': 364,\n",
       " '6days': 762,\n",
       " '16': 382,\n",
       " 'TsandCs': 4047,\n",
       " 'Reply': 3413,\n",
       " 'HL': 2138,\n",
       " '4': 605,\n",
       " 'info': 7353,\n",
       " 'URGENT': 4089,\n",
       " '1': 292,\n",
       " 'week': 11005,\n",
       " 'membership': 8109,\n",
       " '£100000': 11364,\n",
       " 'Prize': 3282,\n",
       " 'Jackpot': 2420,\n",
       " 'Txt': 4061,\n",
       " 'CLAIM': 1377,\n",
       " '81010': 820,\n",
       " 'TC': 3846,\n",
       " 'wwwdbuknet': 11230,\n",
       " 'LCCLTD': 2550,\n",
       " 'POBOX': 3137,\n",
       " '4403LDNW1A7RW18': 626,\n",
       " 'searching': 9596,\n",
       " 'right': 9421,\n",
       " 'words': 11153,\n",
       " 'thank': 10391,\n",
       " 'breather': 5165,\n",
       " 'promise': 9091,\n",
       " 'wont': 11144,\n",
       " 'take': 10294,\n",
       " 'help': 7088,\n",
       " 'granted': 6928,\n",
       " 'fulfil': 6750,\n",
       " 'wonderful': 11141,\n",
       " 'blessing': 5074,\n",
       " 'times': 10490,\n",
       " 'DATE': 1567,\n",
       " 'SUNDAY': 3566,\n",
       " 'XXXMobileMovieClub': 4369,\n",
       " 'use': 10792,\n",
       " 'credit': 5773,\n",
       " 'click': 5539,\n",
       " 'WAP': 4199,\n",
       " 'link': 7817,\n",
       " 'next': 8419,\n",
       " 'message': 8132,\n",
       " 'httpwap': 7223,\n",
       " 'xxxmobilemovieclubcomnQJKGIGHJJGCBL': 11272,\n",
       " 'Oh': 3058,\n",
       " 'kim': 7617,\n",
       " 'watching': 10969,\n",
       " 'Eh': 1768,\n",
       " 'remember': 9318,\n",
       " 'spell': 9984,\n",
       " 'name': 8347,\n",
       " 'Yes': 4424,\n",
       " 'v': 10815,\n",
       " 'naughty': 8367,\n",
       " 'make': 7999,\n",
       " 'wet': 11039,\n",
       " 'Fine': 1913,\n",
       " 'that\\x92s': 10404,\n",
       " 'way': 10978,\n",
       " 'feel': 6516,\n",
       " 'That\\x92s': 3963,\n",
       " 'gota': 6906,\n",
       " 'b': 4879,\n",
       " 'England': 1783,\n",
       " 'Macedonia': 2771,\n",
       " 'miss': 8190,\n",
       " 'goalsteam': 6869,\n",
       " 'news': 8414,\n",
       " 'ur': 10776,\n",
       " 'national': 8361,\n",
       " 'team': 10337,\n",
       " '87077': 869,\n",
       " 'eg': 6257,\n",
       " 'ENGLAND': 1727,\n",
       " 'TryWALES': 4041,\n",
       " 'SCOTLAND': 3459,\n",
       " '4txtú120': 677,\n",
       " 'POBOXox36504W45WQ': 3140,\n",
       " 'seriously': 9657,\n",
       " 'I‘m': 2400,\n",
       " 'going': 6881,\n",
       " 'try': 10654,\n",
       " 'ha': 6991,\n",
       " 'joking': 7533,\n",
       " 'ü': 11417,\n",
       " 'pay': 8768,\n",
       " 'first': 6583,\n",
       " 'da': 5831,\n",
       " 'stock': 10096,\n",
       " 'comin': 5608,\n",
       " 'Aft': 1018,\n",
       " 'finish': 6569,\n",
       " 'lunch': 7946,\n",
       " 'go': 6863,\n",
       " 'str': 10116,\n",
       " 'lor': 7887,\n",
       " 'Ard': 1083,\n",
       " 'smth': 9880,\n",
       " 'Ffffffffff': 1904,\n",
       " 'Alright': 1052,\n",
       " 'meet': 8091,\n",
       " 'sooner': 9931,\n",
       " 'forced': 6654,\n",
       " 'eat': 6233,\n",
       " 'slice': 9835,\n",
       " 'really': 9233,\n",
       " 'hungry': 7248,\n",
       " 'tho': 10445,\n",
       " 'sucks': 10185,\n",
       " 'Mark': 2793,\n",
       " 'getting': 6831,\n",
       " 'worried': 11168,\n",
       " 'knows': 7642,\n",
       " 'sick': 9763,\n",
       " 'turn': 10671,\n",
       " 'pizza': 8868,\n",
       " 'Lol': 2647,\n",
       " 'always': 4640,\n",
       " 'convincing': 5702,\n",
       " 'catch': 5373,\n",
       " 'bus': 5236,\n",
       " 'frying': 6740,\n",
       " 'egg': 6259,\n",
       " 'tea': 10331,\n",
       " 'eating': 6236,\n",
       " 'moms': 8234,\n",
       " 'left': 7747,\n",
       " 'dinner': 6044,\n",
       " 'Love': 2660,\n",
       " 'amp': 4654,\n",
       " 'packing': 8692,\n",
       " 'car': 5330,\n",
       " 'Ill': 2349,\n",
       " 'let': 7768,\n",
       " 'know': 7638,\n",
       " 'theres': 10420,\n",
       " 'room': 9459,\n",
       " 'Ahhh': 1027,\n",
       " 'Work': 4344,\n",
       " 'vaguely': 10818,\n",
       " 'Wait': 4255,\n",
       " 'thats': 10403,\n",
       " 'clear': 5533,\n",
       " 'sure': 10236,\n",
       " 'sarcastic': 9535,\n",
       " 'x': 11259,\n",
       " 'doesnt': 6098,\n",
       " 'live': 7838,\n",
       " 'us': 10786,\n",
       " 'Yeah': 4415,\n",
       " 'apologetic': 4718,\n",
       " 'fallen': 6467,\n",
       " 'actin': 4508,\n",
       " 'spoilt': 10004,\n",
       " 'child': 5482,\n",
       " 'caught': 5377,\n",
       " 'Till': 3996,\n",
       " 'badly': 4897,\n",
       " 'cheers': 5449,\n",
       " 'K': 2467,\n",
       " 'tell': 10353,\n",
       " 'anything': 4706,\n",
       " 'fear': 6508,\n",
       " 'fainting': 6458,\n",
       " 'housework': 7204,\n",
       " 'Quick': 3315,\n",
       " 'cuppa': 5809,\n",
       " 'Thanks': 3957,\n",
       " 'subscription': 10175,\n",
       " 'Ringtone': 3423,\n",
       " 'UK': 4073,\n",
       " 'charged': 5422,\n",
       " '£5month': 11403,\n",
       " 'Please': 3234,\n",
       " 'confirm': 5660,\n",
       " 'replying': 9350,\n",
       " 'YES': 4387,\n",
       " 'reply': 9348,\n",
       " 'Yup': 4449,\n",
       " 'look': 7879,\n",
       " 'timings': 10496,\n",
       " 'msg': 8282,\n",
       " 'Xuhui': 4376,\n",
       " 'learn': 7736,\n",
       " '2nd': 526,\n",
       " 'may': 8064,\n",
       " 'lesson': 7766,\n",
       " '8am': 902,\n",
       " 'Oops': 3084,\n",
       " 'roommates': 9462,\n",
       " 'done': 6119,\n",
       " 'see': 9612,\n",
       " 'letter': 7770,\n",
       " 'B': 1119,\n",
       " 'Anything': 1069,\n",
       " 'decide': 5914,\n",
       " 'Hello': 2208,\n",
       " 'Hows': 2278,\n",
       " 'saturday': 9545,\n",
       " 'texting': 10382,\n",
       " 'youd': 11317,\n",
       " 'decided': 5915,\n",
       " 'tomo': 10545,\n",
       " 'im': 7306,\n",
       " 'trying': 10656,\n",
       " 'invite': 7409,\n",
       " 'Pls': 3236,\n",
       " 'ahead': 4581,\n",
       " 'watts': 10976,\n",
       " 'wanted': 10946,\n",
       " 'weekend': 11007,\n",
       " 'Abiola': 998,\n",
       " 'forget': 6660,\n",
       " 'need': 8385,\n",
       " 'crave': 5765,\n",
       " 'love': 7912,\n",
       " 'sweet': 10260,\n",
       " 'Arabian': 1081,\n",
       " 'steed': 10078,\n",
       " 'Mmmmmm': 2845,\n",
       " 'Yummy': 4446,\n",
       " '07732584351': 29,\n",
       " 'Rodger': 3429,\n",
       " 'Burns': 1328,\n",
       " 'MSG': 2756,\n",
       " 'tried': 10637,\n",
       " 'sms': 9875,\n",
       " 'free': 6698,\n",
       " 'nokia': 8454,\n",
       " 'camcorder': 5301,\n",
       " '08000930705': 54,\n",
       " 'delivery': 5949,\n",
       " 'tomorrow': 10548,\n",
       " 'SEEING': 3463,\n",
       " 'Great': 2087,\n",
       " 'hope': 7176,\n",
       " 'man': 8008,\n",
       " 'well': 11022,\n",
       " 'endowed': 6302,\n",
       " 'ltgt': 7938,\n",
       " 'inches': 7332,\n",
       " 'callsmessagesmissed': 5297,\n",
       " 'calls': 5296,\n",
       " 'Didnt': 1662,\n",
       " 'get': 6823,\n",
       " 'hep': 7097,\n",
       " 'immunisation': 7314,\n",
       " 'nigeria': 8426,\n",
       " 'Fair': 1892,\n",
       " 'hopefully': 7181,\n",
       " 'tyler': 10691,\n",
       " 'cant': 5319,\n",
       " 'could': 5737,\n",
       " 'maybe': 8066,\n",
       " 'ask': 4798,\n",
       " 'bit': 5052,\n",
       " 'stubborn': 10142,\n",
       " 'didnt': 6013,\n",
       " 'even': 6368,\n",
       " 'hospital': 7191,\n",
       " 'kept': 7593,\n",
       " 'telling': 10354,\n",
       " 'weak': 10982,\n",
       " 'sucker': 10183,\n",
       " 'Hospitals': 2270,\n",
       " 'suckers': 10184,\n",
       " 'thinked': 10434,\n",
       " 'First': 1917,\n",
       " 'time': 10486,\n",
       " 'saw': 9552,\n",
       " 'class': 5526,\n",
       " 'gram': 6922,\n",
       " 'usually': 10804,\n",
       " 'runs': 9494,\n",
       " 'half': 7003,\n",
       " 'eighth': 6266,\n",
       " 'smarter': 9857,\n",
       " 'gets': 6827,\n",
       " 'almost': 4624,\n",
       " 'whole': 11062,\n",
       " 'second': 9600,\n",
       " 'fyi': 6767,\n",
       " 'ride': 9420,\n",
       " 'morning': 8255,\n",
       " 'hes': 7108,\n",
       " 'crashing': 5764,\n",
       " 'place': 8869,\n",
       " 'Wow': 4351,\n",
       " 'never': 8409,\n",
       " 'realized': 9231,\n",
       " 'embarassed': 6286,\n",
       " 'accomodations': 4491,\n",
       " 'thought': 10450,\n",
       " 'liked': 7800,\n",
       " 'since': 9787,\n",
       " 'best': 5013,\n",
       " 'seemed': 9618,\n",
       " 'happy': 7034,\n",
       " 'cave': 5381,\n",
       " 'sorry': 9940,\n",
       " 'give': 6849,\n",
       " 'offered': 8546,\n",
       " 'embarassing': 6287,\n",
       " 'SMS': 3505,\n",
       " 'ac': 4477,\n",
       " 'Sptv': 3761,\n",
       " 'New': 2967,\n",
       " 'Jersey': 2440,\n",
       " 'Devils': 1656,\n",
       " 'Detroit': 1655,\n",
       " 'Red': 3393,\n",
       " 'Wings': 4321,\n",
       " 'play': 8883,\n",
       " 'Ice': 2343,\n",
       " 'Hockey': 2248,\n",
       " 'Correct': 1521,\n",
       " 'Incorrect': 2359,\n",
       " 'End': 1781,\n",
       " 'END': 1725,\n",
       " 'SPTV': 3537,\n",
       " 'Mallika': 2783,\n",
       " 'Sherawat': 3652,\n",
       " 'yesterday': 11298,\n",
       " 'Find': 1912,\n",
       " 'ltURLgt': 7937,\n",
       " 'Congrats': 1512,\n",
       " 'year': 11289,\n",
       " 'special': 9972,\n",
       " 'cinema': 5514,\n",
       " 'pass': 8749,\n",
       " '09061209465': 214,\n",
       " 'C': 1336,\n",
       " 'Suprman': 3820,\n",
       " 'V': 4144,\n",
       " 'Matrix3': 2800,\n",
       " 'StarWars3': 3770,\n",
       " 'etc': 6358,\n",
       " 'bx420ip45we': 5255,\n",
       " '150pm': 365,\n",
       " 'Dont': 1693,\n",
       " 'Sorry': 3734,\n",
       " 'later': 7713,\n",
       " 'meeting': 8093,\n",
       " 'Tell': 3941,\n",
       " 'reached': 9215,\n",
       " 'Yesgauti': 4427,\n",
       " 'sehwag': 9624,\n",
       " 'odi': 8540,\n",
       " 'series': 9655,\n",
       " 'pick': 8843,\n",
       " 'burger': 5228,\n",
       " 'move': 8269,\n",
       " 'Pain': 3179,\n",
       " 'killing': 7614,\n",
       " 'Ha': 2167,\n",
       " 'good': 6891,\n",
       " 'joke': 7528,\n",
       " 'Girls': 2054,\n",
       " 'situation': 9807,\n",
       " 'seekers': 9615,\n",
       " 'part': 8738,\n",
       " 'checking': 5446,\n",
       " 'IQ': 2328,\n",
       " 'took': 10565,\n",
       " 'forever': 6657,\n",
       " 'come': 5600,\n",
       " 'double': 6133,\n",
       " 'check': 5443,\n",
       " 'hair': 7000,\n",
       " 'dresser': 6161,\n",
       " 'said': 9511,\n",
       " 'wun': 11207,\n",
       " 'cut': 5822,\n",
       " 'short': 9729,\n",
       " 'nice': 8422,\n",
       " 'pleased': 8894,\n",
       " 'advise': 4546,\n",
       " 'following': 6638,\n",
       " 'recent': 9255,\n",
       " 'review': 9410,\n",
       " 'Mob': 2848,\n",
       " 'awarded': 4872,\n",
       " '£1500': 11371,\n",
       " 'Bonus': 1281,\n",
       " '09066364589': 263,\n",
       " 'Today': 4010,\n",
       " 'song': 9926,\n",
       " 'dedicated': 5924,\n",
       " 'day': 5880,\n",
       " 'dedicate': 5923,\n",
       " 'Send': 3622,\n",
       " 'valuable': 10824,\n",
       " 'frnds': 6727,\n",
       " 'rply': 9475,\n",
       " 'Urgent': 4134,\n",
       " 'UR': 4086,\n",
       " 'complimentary': 5635,\n",
       " 'trip': 10638,\n",
       " 'EuroDisinc': 1798,\n",
       " 'Trav': 4031,\n",
       " 'AcoEntry41': 1007,\n",
       " '£1000': 11362,\n",
       " 'DIS': 1586,\n",
       " '186£150moreFrmMob': 391,\n",
       " 'ShrAcomOrSglSuplt10': 3672,\n",
       " 'LS1': 2588,\n",
       " '3AJ': 576,\n",
       " 'hear': 7065,\n",
       " 'new': 8412,\n",
       " 'Divorce': 1678,\n",
       " 'Barbie': 1224,\n",
       " 'comes': 5604,\n",
       " 'Kens': 2496,\n",
       " 'plane': 8876,\n",
       " 'month': 8247,\n",
       " 'end': 6297,\n",
       " 'Wah': 4253,\n",
       " 'lucky': 7943,\n",
       " 'save': 9548,\n",
       " 'money': 8240,\n",
       " 'Hee': 2202,\n",
       " 'Finished': 1916,\n",
       " 'HI': 2134,\n",
       " 'BABE': 1123,\n",
       " 'IM': 2307,\n",
       " 'HOME': 2144,\n",
       " 'WANNA': 4196,\n",
       " 'SOMETHING': 3514,\n",
       " 'XX': 4366,\n",
       " 'Kkwhere': 2526,\n",
       " 'youhow': 11320,\n",
       " 'performed': 8802,\n",
       " 'waiting': 10923,\n",
       " 'machan': 7968,\n",
       " 'Thats': 3962,\n",
       " 'cool': 5708,\n",
       " 'gentleman': 6817,\n",
       " 'dignity': 6035,\n",
       " 'respect': 9376,\n",
       " 'peoples': 8794,\n",
       " 'much': 8298,\n",
       " 'shy': 9759,\n",
       " 'pa': 8687,\n",
       " 'operate': 8605,\n",
       " 'Still': 3782,\n",
       " 'looking': 7882,\n",
       " 'job': 7515,\n",
       " 'Tas': 3926,\n",
       " 'earn': 6222,\n",
       " 'ah': 4579,\n",
       " 'hi': 7115,\n",
       " 'stop': 10105,\n",
       " 'urgnt': 10781,\n",
       " 'real': 9225,\n",
       " 'yo': 11307,\n",
       " 'tickets': 10477,\n",
       " 'one': 8585,\n",
       " 'jacket': 7476,\n",
       " 'used': 10793,\n",
       " 'multis': 8306,\n",
       " 'started': 10053,\n",
       " 'requests': 9356,\n",
       " 'pain': 8699,\n",
       " 'came': 5302,\n",
       " 'bed': 4972,\n",
       " 'Double': 1699,\n",
       " 'coins': 5579,\n",
       " 'factory': 6450,\n",
       " 'gotta': 6909,\n",
       " 'cash': 5362,\n",
       " 'nitros': 8444,\n",
       " 'babe': 4884,\n",
       " 'Ela': 1771,\n",
       " 'kanoil': 7576,\n",
       " 'download': 6139,\n",
       " 'wen': 11027,\n",
       " 'Don‘t': 1696,\n",
       " 'stand': 10042,\n",
       " 'close': 5545,\n",
       " 'you‘ll': 11337,\n",
       " 'something': 9914,\n",
       " 'another': 4685,\n",
       " 'night': 8427,\n",
       " 'spent': 9989,\n",
       " 'late': 7708,\n",
       " 'afternoon': 4562,\n",
       " 'casualty': 5371,\n",
       " 'means': 8082,\n",
       " 'havent': 7050,\n",
       " 'stuff42moro': 10153,\n",
       " 'includes': 7335,\n",
       " 'sheets': 9698,\n",
       " 'Smile': 3712,\n",
       " 'Pleasure': 3235,\n",
       " 'trouble': 10643,\n",
       " 'pours': 8976,\n",
       " 'Rain': 3367,\n",
       " 'sum1': 10203,\n",
       " 'Hurts': 2288,\n",
       " 'becoz': 4970,\n",
       " 'SOMEONE': 3512,\n",
       " 'Loves': 2666,\n",
       " 'Smiling': 3714,\n",
       " 'service': 9660,\n",
       " 'representative': 9353,\n",
       " '0800': 50,\n",
       " '169': 384,\n",
       " '6031': 726,\n",
       " '10am9pm': 309,\n",
       " 'guaranteed': 6968,\n",
       " '£5000': 11398,\n",
       " 'Havent': 2193,\n",
       " 'planning': 8880,\n",
       " 'buy': 5247,\n",
       " 'lido': 7782,\n",
       " '530': 697,\n",
       " 'show': 9743,\n",
       " 'work': 11154,\n",
       " 'ringtone': 9428,\n",
       " 'collected': 5586,\n",
       " 'Simply': 3682,\n",
       " 'text': 10377,\n",
       " 'password': 8757,\n",
       " 'MIX': 2731,\n",
       " '85069': 855,\n",
       " 'verify': 10845,\n",
       " 'Get': 2046,\n",
       " 'Usher': 4139,\n",
       " 'Britney': 1314,\n",
       " 'FML': 1856,\n",
       " 'PO': 3135,\n",
       " 'Box': 1291,\n",
       " '5249': 694,\n",
       " 'MK17': 2732,\n",
       " '92H': 913,\n",
       " '450Ppw': 636,\n",
       " 'Watching': 4276,\n",
       " 'telugu': 10358,\n",
       " 'moviewat': 8274,\n",
       " 'abt': 4473,\n",
       " 'loads': 7849,\n",
       " 'loans': 7851,\n",
       " 'Hi': 2224,\n",
       " 'Wk': 4330,\n",
       " 'hols': 7156,\n",
       " 'run': 9491,\n",
       " 'Forgot': 1933,\n",
       " 'hairdressers': 7002,\n",
       " 'appointment': 4734,\n",
       " 'four': 6684,\n",
       " 'shower': 9745,\n",
       " 'beforehand': 4984,\n",
       " 'cause': 5378,\n",
       " 'prob': 9061,\n",
       " 'cup': 5807,\n",
       " 'coffee': 5574,\n",
       " 'animation': 4672,\n",
       " 'nothing': 8479,\n",
       " 'else': 6281,\n",
       " 'Okay': 3064,\n",
       " 'price': 9037,\n",
       " 'long': 7875,\n",
       " 'legal': 7750,\n",
       " 'Wen': 4294,\n",
       " 'ave': 4860,\n",
       " 'ams': 4656,\n",
       " 'xx': 11269,\n",
       " 'gone': 6887,\n",
       " '4the': 675,\n",
       " 'driving': 6170,\n",
       " 'test': 10373,\n",
       " 'yet': 11299,\n",
       " 'wow': 11183,\n",
       " 'Youre': 4442,\n",
       " 'mean': 8078,\n",
       " 'guess': 6972,\n",
       " 'gave': 6798,\n",
       " 'boston': 5125,\n",
       " 'men': 8114,\n",
       " 'changed': 5412,\n",
       " 'search': 9595,\n",
       " 'location': 7854,\n",
       " 'nyc': 8518,\n",
       " 'Cuz': 1559,\n",
       " 'signin': 9773,\n",
       " 'page': 8695,\n",
       " 'says': 9558,\n",
       " 'Umma': 4109,\n",
       " 'life': 7785,\n",
       " 'vava': 10835,\n",
       " 'umma': 10710,\n",
       " 'lot': 7896,\n",
       " 'dear': 5901,\n",
       " 'wishes': 11103,\n",
       " 'birthday': 5050,\n",
       " 'making': 8003,\n",
       " 'truly': 10650,\n",
       " 'memorable': 8111,\n",
       " 'Aight': 1030,\n",
       " 'hit': 7134,\n",
       " 'would': 11179,\n",
       " 'ip': 7417,\n",
       " 'address': 4523,\n",
       " 'considering': 5677,\n",
       " 'computer': 5641,\n",
       " 'isnt': 7439,\n",
       " 'minecraft': 8169,\n",
       " 'server': 9659,\n",
       " 'Grumpy': 2091,\n",
       " 'old': 8579,\n",
       " 'people': 8793,\n",
       " 'mom': 8231,\n",
       " 'better': 5019,\n",
       " 'lying': 7959,\n",
       " 'jokes': 7530,\n",
       " 'worry': 11170,\n",
       " 'busy': 5242,\n",
       " 'plural': 8904,\n",
       " 'noun': 8486,\n",
       " 'research': 9362,\n",
       " 'Going': 2065,\n",
       " 'dinnermsg': 6045,\n",
       " 'cos': 5726,\n",
       " 'things': 10431,\n",
       " 'scared': 9564,\n",
       " 'mah': 7989,\n",
       " 'Cos': 1522,\n",
       " 'loud': 7907,\n",
       " 'GENT': 1978,\n",
       " 'contact': 5682,\n",
       " 'Last': 2606,\n",
       " 'weekends': 11008,\n",
       " 'draw': 6149,\n",
       " 'shows': 9750,\n",
       " 'GUARANTEED': 2021,\n",
       " '09064012160': 238,\n",
       " 'Code': 1493,\n",
       " 'K52': 2468,\n",
       " '12hrs': 338,\n",
       " '150ppm': 370,\n",
       " 'Wa': 4251,\n",
       " 'openin': 8602,\n",
       " 'sentence': 9649,\n",
       " 'formal': 6668,\n",
       " 'Anyway': 1071,\n",
       " 'fine': 6564,\n",
       " 'juz': 7559,\n",
       " 'tt': 10660,\n",
       " 'eatin': 6235,\n",
       " 'puttin': 9142,\n",
       " 'weightHaha': 11015,\n",
       " 'anythin': 4705,\n",
       " 'happened': 7026,\n",
       " 'entered': 6320,\n",
       " 'cabin': 5262,\n",
       " 'PA': 3103,\n",
       " 'Happy': 2185,\n",
       " 'Bday': 1231,\n",
       " 'Boss': 1289,\n",
       " 'felt': 6525,\n",
       " 'askd': 4799,\n",
       " 'invited': 7410,\n",
       " 'apartment': 4714,\n",
       " 'went': 11029,\n",
       " 'winner': 11093,\n",
       " 'specially': 9976,\n",
       " 'holiday': 7152,\n",
       " 'flights': 6608,\n",
       " 'inc': 7330,\n",
       " 'operator': 8606,\n",
       " '0871277810910pmin': 123,\n",
       " '18': 387,\n",
       " 'Goodo': 2074,\n",
       " 'must': 8323,\n",
       " 'friday': 6711,\n",
       " 'eggpotato': 6260,\n",
       " 'ratio': 9202,\n",
       " 'tortilla': 10582,\n",
       " 'needed': 8387,\n",
       " 'Hmmmy': 2245,\n",
       " 'uncle': 10715,\n",
       " 'informed': 7357,\n",
       " 'paying': 8772,\n",
       " 'school': 9570,\n",
       " 'directly': 6049,\n",
       " 'pls': 8900,\n",
       " 'food': 6644,\n",
       " 'PRIVATE': 3165,\n",
       " '2004': 429,\n",
       " 'Account': 1003,\n",
       " 'Statement': 3775,\n",
       " '07742676969': 31,\n",
       " '786': 787,\n",
       " 'unredeemed': 10753,\n",
       " 'Points': 3250,\n",
       " '08719180248': 171,\n",
       " 'Identifier': 2347,\n",
       " '45239': 639,\n",
       " 'Expires': 1824,\n",
       " '£2000': 11383,\n",
       " 'Caller': 1419,\n",
       " '5903': 702,\n",
       " 'Landline': 2601,\n",
       " '09064019788': 244,\n",
       " 'BOX42WR29C': 1184,\n",
       " '150PPM': 355,\n",
       " 'applespairsall': 4728,\n",
       " 'malarky': 8005,\n",
       " 'Todays': 4011,\n",
       " 'Voda': 4178,\n",
       " 'numbers': 8509,\n",
       " 'ending': 6299,\n",
       " '7548': 782,\n",
       " '350': 566,\n",
       " 'award': 4871,\n",
       " 'match': 8045,\n",
       " 'please': 8893,\n",
       " '08712300220': 105,\n",
       " 'quoting': 9169,\n",
       " '4041': 610,\n",
       " 'standard': 10043,\n",
       " 'rates': 9200,\n",
       " 'app': 4722,\n",
       " 'sao': 9530,\n",
       " 'mu': 8297,\n",
       " 'Ü': 11414,\n",
       " 'predict': 9004,\n",
       " 'üll': 11418,\n",
       " 'buying': 5250,\n",
       " 'Good': 2069,\n",
       " 'knowyetunde': 7645,\n",
       " 'hasnt': 7041,\n",
       " 'sent': 9648,\n",
       " 'bother': 5127,\n",
       " 'sending': 9641,\n",
       " 'involve': 7414,\n",
       " 'shouldnt': 9737,\n",
       " 'imposed': 7320,\n",
       " 'apologise': 4719,\n",
       " 'HEY': 2130,\n",
       " 'GIRL': 1984,\n",
       " 'HOPE': 2148,\n",
       " 'WELL': 4206,\n",
       " 'DEL': 1579,\n",
       " 'BAK': 1133,\n",
       " 'LONG': 2574,\n",
       " 'TIME': 3882,\n",
       " 'GIVE': 1987,\n",
       " 'CALL': 1340,\n",
       " 'SUM': 3563,\n",
       " 'LUCYxx': 2594,\n",
       " 'Kkhow': 2520,\n",
       " 'cost': 5728,\n",
       " 'Dear': 1633,\n",
       " 'Tmorrowpls': 4004,\n",
       " 'accomodate': 4490,\n",
       " 'answer': 4688,\n",
       " 'question': 9155,\n",
       " 'Sunshine': 3816,\n",
       " 'Quiz': 3317,\n",
       " 'Wkly': 4331,\n",
       " 'Q': 3303,\n",
       " 'Win': 4319,\n",
       " 'top': 10573,\n",
       " 'Sony': 3731,\n",
       " 'DVD': 1613,\n",
       " 'player': 8885,\n",
       " 'country': 5743,\n",
       " 'Algarve': 1046,\n",
       " 'ansr': 4687,\n",
       " '82277': 826,\n",
       " 'SPTyrone': 3538,\n",
       " 'Want': 4266,\n",
       " 'laid': 7680,\n",
       " 'Dogging': 1687,\n",
       " 'locations': 7855,\n",
       " 'direct': 6048,\n",
       " 'mob': 8214,\n",
       " 'Join': 2446,\n",
       " 'UKs': 4076,\n",
       " 'largest': 7702,\n",
       " 'Network': 2962,\n",
       " 'bt': 5206,\n",
       " 'Txting': 4064,\n",
       " 'GRAVEL': 2017,\n",
       " '69888': 751,\n",
       " 'Nt': 3019,\n",
       " 'ec2a': 6238,\n",
       " '31pmsg150p': 559,\n",
       " 'haf': 6996,\n",
       " 'msn': 8292,\n",
       " 'yijuehotmailcom': 11305,\n",
       " 'rooms': 9463,\n",
       " 'befor': 4983,\n",
       " 'activities': 4513,\n",
       " 'Youll': 4441,\n",
       " 'msgs': 8285,\n",
       " 'chat': 5434,\n",
       " 'svc': 10251,\n",
       " 'Hardcore': 2187,\n",
       " 'services': 9661,\n",
       " 'GO': 1992,\n",
       " '69988': 755,\n",
       " 'Age': 1024,\n",
       " 'Verify': 4168,\n",
       " 'yr': 11340,\n",
       " 'Got': 2079,\n",
       " 'lazy': 7730,\n",
       " 'type': 10693,\n",
       " 'forgot': 6665,\n",
       " 'lect': 7744,\n",
       " 'pouch': 8971,\n",
       " 'youre': 11328,\n",
       " 'Sir': 3689,\n",
       " 'Waiting': 4258,\n",
       " 'mail': 7992,\n",
       " 'swt': 10272,\n",
       " 'Nver': 3024,\n",
       " 'tired': 10500,\n",
       " 'little': 7837,\n",
       " 'lovable': 7911,\n",
       " 'persons': 8816,\n",
       " 'Cozsomtimes': 1531,\n",
       " 'occupy': 8534,\n",
       " 'biggest': 5034,\n",
       " 'Hearts': 2201,\n",
       " 'Gud': 2095,\n",
       " 'ni8': 8420,\n",
       " 'open': 8599,\n",
       " 'ya': 11278,\n",
       " 'dot': 6132,\n",
       " 'Whats': 4303,\n",
       " 'staff': 10033,\n",
       " 'taking': 10299,\n",
       " 'replied': 9346,\n",
       " 'Randy': 3374,\n",
       " 'sexy': 9675,\n",
       " 'female': 6526,\n",
       " 'local': 7853,\n",
       " 'Luv': 2679,\n",
       " 'Netcollex': 2961,\n",
       " ...}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vocabulario nos dice el numero asignado a cada palabra\n",
    "bow_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11424\n"
     ]
    }
   ],
   "source": [
    "# Imprime el número total de palabras de vocabulario\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5571, 11424)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#si transformamos todos nuestros mensajes tenemos una bolsa de valores de la siguiente estructura.. tarda un poco..\n",
    "bow_transformer.transform(messages['mensaje']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5,571 mensajes que contienen 11,424 palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos un mensaje de texto y obtengamos su bolsa de palabras como un vector, poniendo en uso nuestro nuevo `bow_transformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "message4 = messages['mensaje'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos su representación vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4067)\t2\n",
      "  (0, 4628)\t1\n",
      "  (0, 5260)\t1\n",
      "  (0, 6203)\t1\n",
      "  (0, 6221)\t1\n",
      "  (0, 7185)\t1\n",
      "  (0, 9553)\t2\n",
      "filas, columnas:\n",
      "(1, 11424)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print('filas, columnas:')\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que hay siete palabras únicas en el mensaje número 4 (después de eliminar las palabras vacías comunes). Dos de ellos aparecen dos veces, el resto solo una vez. Sigamos adelante y verifiquemos y confirmemos cuáles aparecen dos veces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "say\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[4067])\n",
    "print(bow_transformer.get_feature_names()[9553])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usar **.transform** en nuestro objeto transformado Bag-of-Words (bow) y transformar todo el DataFrame de mensajes. Sigamos adelante y veamos cómo la bolsa de palabras cuenta para todo el corpus de SMS es una matriz grande y dispersa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_bow = bow_transformer.transform(messages['mensaje'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructura de la Matriz Dispersa:  (5571, 11424)\n"
     ]
    }
   ],
   "source": [
    "print('Estructura de la Matriz Dispersa: ', messages_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entonces, ¿qué es TF-IDF?\n",
    "TF-IDF significa *frecuencia de terminos-frecuencia inversa de documentos (term frequency-inverse document frequency)*, y la ponderación tf-idf es una ponderación que se utiliza a menudo en la recuperación de información y la minería de texto. Este peso es una medida estadística que se utiliza para evaluar la importancia de una palabra para un documento en una colección o corpus. La importancia aumenta proporcionalmente al número de veces que aparece una palabra en el documento, pero se compensa con la frecuencia de la palabra en el corpus. Los motores de búsqueda suelen utilizar variaciones del esquema de ponderación tf-idf como una herramienta central para calificar y clasificar la relevancia de un documento dada una consulta de usuario.\n",
    "\n",
    "Una de las funciones de clasificación más simples se calcula sumando tf-idf para cada término de consulta; muchas funciones de clasificación más sofisticadas son variantes de este modelo simple.\n",
    "\n",
    "Por lo general, el peso tf-idf se compone de dos términos: el primero calcula la frecuencia de término normalizada (TF), también conocida como el número de veces que aparece una palabra en un texto, dividido por el número total de palabras en ese texto; el segundo término es la Frecuencia Inversa de Documentos (IDF), calculada como el logaritmo del número de texto en el corpus dividido por el número de texto donde aparece el término específico.\n",
    "\n",
    "**TF: Término Frecuencia**, que mide la frecuencia con la que aparece un término en un documento. Dado que cada texto tiene una longitud diferente, es posible que un término aparezca muchas más veces en textos largos que en textos más cortos. Por lo tanto, la frecuencia de los términos a menudo se divide por la longitud del documento (también conocido como el número total de términos en el texto) como una forma de normalización:\n",
    "\n",
    "*TF (t) = (Número de veces que aparece el término t en un texto) / (Número total de términos en el texto).*\n",
    "\n",
    "**IDF: Frecuencia de documentos inversa**, que mide la importancia de un término. Al calcular TF, todos los términos se consideran igualmente importantes. Sin embargo, se sabe que ciertos términos, como \"es\", \"de\" y \"eso\", pueden aparecer muchas veces pero tienen poca importancia. Por lo tanto, debemos sopesar los términos frecuentes mientras aumentamos los raros, calculando lo siguiente:\n",
    "\n",
    "*IDF(t) = log_e (Número total de textos / Número de texto con el término t).*\n",
    "\n",
    "Vea a continuación un ejemplo simple.\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "Considere un texto que contiene 100 palabras en el que la palabra gato aparece 3 veces.\n",
    "\n",
    "El término frecuencia (es decir, tf) para gato es entonces (3/100) = 0.03. Ahora, suponga que tenemos 10 millones de textos y la palabra gato aparece en mil de ellos. Entonces, la frecuencia inversa del documento (es decir, idf) se calcula como log (10,000,000 / 1,000) = 4. Por lo tanto, el peso Tf-idf es el producto de estas cantidades: 0.03 * 4 = 0.12.\n",
    "____\n",
    "\n",
    "Sigamos adelante y veamos cómo podemos hacer esto en SciKit Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9553)\t0.5385616356475857\n",
      "  (0, 7185)\t0.43894157799744\n",
      "  (0, 6221)\t0.31872279909035767\n",
      "  (0, 6203)\t0.2995384842198017\n",
      "  (0, 5260)\t0.2972999883694666\n",
      "  (0, 4628)\t0.2661974236368854\n",
      "  (0, 4067)\t0.40832068045792724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguiremos adelante y comprobaremos cuál es el IDF (frecuencia inversa de documentos) de la palabra `\" u \"` y de la palabra `\" universidad \"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2798729740711003\n",
      "8.526897046231586\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\n",
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['university']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar todo el corpus de la bolsa de palabras en el corpus TF-IDF a la vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5571, 11424)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchas formas de preprocesar y vectorizar los datos. Estos pasos implican la ingeniería de variables y la construcción de un \"pipeline\". Le animo a que consulte la documentación de SciKit Learn sobre el manejo de datos de texto, así como la amplia colección de artículos y libros disponibles sobre el tema general de la PNL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los mensajes representados como vectores, finalmente podemos entrenar nuestro clasificador de spam / ham. Ahora podemos utilizar casi cualquier tipo de algoritmo de clasificación. Por una [variedad de razones](http://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn-note07-2up.pdf), el algoritmo clasificador Naive Bayes es una buena opción ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos scikit-learn aquí, eligiendo el clasificador [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) para comenzar con:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(messages_tfidf, \n",
    "                                                                messages['label'], \n",
    "                                                                test_size=0.2)\n",
    "\n",
    "spam_detect_model = MultinomialNB().fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[966  45]\n",
      " [  0 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.96      0.98      1011\n",
      "        spam       0.70      1.00      0.82       104\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.85      0.98      0.90      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(spam_detect_model.predict(msg_test), label_test))\n",
    "print(classification_report(spam_detect_model.predict(msg_test), label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tamaño de la prueba es el 20% de todo el conjunto de datos (1115 mensajes de un total de 5572) y el entrenamiento es el resto (4457 de 5572). Tenga en cuenta que la división predeterminada habría sido 30/70.\n",
    "\n",
    "## Creando un pipeline de datos\n",
    "\n",
    "Ejecutemos nuestro modelo nuevamente y luego pronostiquemos el conjunto de prueba. Usaremos las capacidades de SciKit Learn [pipeline](http://scikit-learn.org/stable/modules/pipeline.html) para almacenar un pipeline de flujo de trabajo. Esto nos permitirá configurar todas las transformaciones que haremos a los datos para uso futuro. Veamos un ejemplo de cómo funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flujo(x):\n",
    "    bow = CountVectorizer(analyzer=text_process).fit_transform(x)\n",
    "    tfidf = TfidfTransformer().fit_transform(bow)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5571x11424 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50547 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flujo(messages['mensaje'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model.predict(flujo(messages['mensaje']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡El procesamiento del lenguaje natural es mucho más de lo que hemos cubierto aquí, y su vasta extensión de tema podría llenar varios cursos universitarios! ¡Le animo a que consulte los recursos a continuación para obtener más información sobre NLP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Más recursos\n",
    "\n",
    "Consulte los enlaces a continuación para obtener más información sobre el procesamiento del lenguaje natural:\n",
    "\n",
    "[NLTK Book Online](http://www.nltk.org/book/)\n",
    "\n",
    "[Kaggle Walkthrough](https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words)\n",
    "\n",
    "[SciKit Learn's Tutorial](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buen trabajo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
